{"meta":{"title":"Suki's Blog","subtitle":null,"description":null,"author":"Suki","url":"https://sukioosuke.github.io"},"posts":[{"title":"样本量大小的确定","slug":"statistics-sample-size","date":"2019-07-25T06:33:40.000Z","updated":"2019-07-26T11:03:41.711Z","comments":true,"path":"2019/07/25/statistics-sample-size/","link":"","permalink":"https://sukioosuke.github.io/2019/07/25/statistics-sample-size/","excerpt":"","text":"估计总体均值时样本量的确定总体均值的置信区间是由样本均值$\\bar x$和估计误差两部分组成的。在重复抽样或者无线总体抽样条件下，估计误差为$z_{\\alpha/2}\\frac\\sigma{\\sqrt n}$。$z_{\\alpha/2}$的值和样本量n共同确定了估计误差的大小。一旦确定了置信水平，临界值$z_{\\alpha/2}$就已经确定了。对于给定的临界值$z_{\\alpha/2}$和总体标准差$\\sigma$，就可以确定任一希望的估计误差所需要的样本量。令E代表所希望达到的估计误差，即：$$ E=z_{\\alpha/2}\\frac\\sigma{\\sqrt n} $$由此可得出样本量n为：$$ n=\\frac{(z_{\\alpha/2})^2\\sigma^2}{E^2} $$在实际应用中，如果$\\sigma$的值不知道，可以用类似样本的标准差来代替；也可以用实验调查的办法，选择一个初始样本，以该样本的样本标准差作为$\\sigma$的估计值。 估计总体比例时样本量的确定与上述估计总体均值时样本量的确定方法类似，在重复抽样或无限总体抽样条件下，估计总体比利置信区间的估计误差为$z_{\\alpha/2}\\sqrt{\\frac{\\pi(1-\\pi)}n}$。$z_{\\alpha/2}$的值、总体比例$\\pi$和样本量n共同决定了误差大小。一旦确定了置信水平，临界值$z_{\\alpha/2}$就已经确定了。由于总体比例的值是固定的，所以估计误差由样本量来确定，样本量越大，估计误差就越小，估计精度就越高。因此，对于给定的临界值$z_{\\alpha/2}，就可以确定任一希望的估计误差所需要的样本量。令E代表所希望达到的估计误差，即：$$ E=z_{\\alpha/2}\\sqrt{\\frac{\\pi(1-\\pi)}n} $$由此可得出样本量n为：$$ n=\\frac{(z_{\\alpha/2})^2\\pi(1-\\pi)}}{E^2} $$在实际应用中，如果$\\pi$值不知道，可以使用类似的样本比例来代替；也可以用实验调查的办法，选择一个初始样本，使用该样本的比例作为$\\pi$的估计值。当$\\pi$值不知道时，通常取使$\\pi(1-\\pi)$最大的0.5。 总结不同置信区间下的临界值 置信区间α 临界值$z_{\\alpha /2}$ 80% 1.282 85% 1.440 90% 1.645 95% 1.960 99% 2.576 99.5% 2.807 99.9% 3.291 一个总体参数的区间估计 参数 点估计量（值） 标准误差 $(1-\\alpha)%$的置信区间 假定条件 μ总体均值 $\\bar{x}$ $\\frac{\\sigma}{\\sqrt{n}}$ $\\bar{x}\\pm z_{\\alpha /2}\\frac{\\sigma}{\\sqrt{n}}$ (1)$\\sigma$已知(2)大样本（$n\\ge 30$） μ总体均值 $\\bar{x}$ $\\frac{\\sigma}{\\sqrt{n}}$ $\\bar{x}\\pm z_{\\alpha /2}\\frac{s}{\\sqrt{n}}$ (1)$\\sigma$未知(2)大样本（$n\\ge 30$） μ总体均值 $\\bar{x}$ $\\frac{\\sigma}{\\sqrt{n}}$ $\\bar{x}\\pm t_{\\alpha /2}\\frac{s}{\\sqrt{n}}$ (1)正态分布(2)$\\sigma$未知(3)小样本（n&lt;30） π总体比例 p $\\sqrt{\\frac{\\pi(1-\\pi)}{n}}$ $p\\pm z_{\\alpha /2}\\sqrt{\\frac{p(1-p)}{n}}$ (1)二项总体(2)大样本（$np \\ge 5,n(1-p) \\ge 5$） $\\sigma^2$总体方差 $s^2$ (不要求) $\\frac{(n-1)s^2}{\\mathcal{X}{\\alpha /2}^{2}}\\le\\sigma^2\\le\\frac{(n-1)s^2}{\\mathcal{X}{1-\\alpha /2}^{2}}$ 正态总体 两个总体参数的区间估计 参数 点估计量（值） 标准误差 $(1-\\alpha)%$的置信区间 假定条件 $\\mu_1-\\mu_2$两个总体均值之差 $\\bar{x_1}-\\bar{x_2}$ $\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ $(\\bar{x_1}-\\bar{x_2})\\pm z_{\\alpha /2}\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ (1)独立大样本($n_1\\ge 30,n_2\\ge 30$)(2)$\\sigma_1,\\sigma_2$已知 $\\mu_1-\\mu_2$两个总体均值之差 $\\bar{x_1}-\\bar{x_2}$ $\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ $(\\bar{x_1}-\\bar{x_2})\\pm z_{\\alpha /2}\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}$ (1)独立大样本($n_1\\ge 30,n_2\\ge 30$)(2)$\\sigma_1,\\sigma_2$未知 $\\mu_1-\\mu_2$两个总体均值之差 $\\bar{x_1}-\\bar{x_2}$ $\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ $(\\bar{x_1}-\\bar{x_2})\\pm t_{\\alpha /2}(n_1+n_2-2)\\sqrt{s_p^2(\\frac{1}{n_1}+\\frac{1}{n_2})}$ (1)两个正态整体(2)独立小样本($n_1&lt;30,n_2&lt;30$)(3)$\\sigma_1,\\sigma_2$未知但相等 $\\mu_1-\\mu_2$两个总体均值之差 $\\bar{x_1}-\\bar{x_2}$ $\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ $(\\bar{x_1}-\\bar{x_2})\\pm t_{\\alpha /2}(v)\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}$ (1)两个正态整体(2)独立小样本($n_1&lt;30,n_2&lt;30$)(3)$\\sigma_1,\\sigma_2$未知且不相等 $\\mu_d=\\mu_1-\\mu_2$两个总体均值之差 $\\bar{d}$ $\\frac{\\sigma_d}{\\sqrt n}$ $\\bar{d}\\pm z_{\\alpha /2}\\frac{\\sigma_d}{\\sqrt n}$ 匹配大样本（$n_1\\ge 30,n_2\\ge 30$） $\\pi_1-\\pi_2$两个总体比例之差 $p_1-p_2$ $\\sqrt{\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2}}$ $(p_1-p_2)\\pm z_{\\alpha /2}\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}$ (1)两个二项总体(2)大样本($n_1 p_1\\ge 5,n1(1-p_1)\\ge 5,n_2 p_2\\ge 5,n_2(1-p_2)\\ge 5$) $\\sigma_1^2/\\sigma_2^2$两个总体方差比 $s_1^2/s_2^2$ (不要求) $\\frac{s_1^2/s_2^2}{F_{\\alpha/2}}\\le\\frac{\\sigma_1^2}{\\sigma_2^2}\\le\\frac{s_1^2/s_2^2}{F_{1-\\alpha/2}$ 两个正态总体","raw":null,"content":null,"categories":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/tags/统计学/"},{"name":"样本","slug":"样本","permalink":"https://sukioosuke.github.io/tags/样本/"}]},{"title":"numpy的简单使用和入门","slug":"python-numpy","date":"2019-07-22T07:16:11.000Z","updated":"2019-07-25T06:32:39.577Z","comments":true,"path":"2019/07/22/python-numpy/","link":"","permalink":"https://sukioosuke.github.io/2019/07/22/python-numpy/","excerpt":"","text":"numpy中数组的建立123import numpy as nparray = np.array([5,7,3,4], dtype=np.int32) 在建立数组时，dtype可以选择int、int32、float、float32等 numpy还可以创建矩阵，同样也是通过array来创建的。同时在创建时可以创建全0、全1、全空数组 123456789101112131415161718192021222324252627282930matrix = np.array([[1, 3, 5],[2, 4, 6]])print(matrix)\"\"\"[[ 1 3 5] [ 2 4 6]]\"\"\"matrix = np.zeros((3,4))\"\"\"array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]])\"\"\"matrix = np.ones((3,4),dtype = np.int)\"\"\"array([[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]])\"\"\"a = np.empty((3,4))\"\"\"array([[ 0.00000000e+000, 4.94065646e-324, 9.88131292e-324, 1.48219694e-323], [ 1.97626258e-323, 2.47032823e-323, 2.96439388e-323, 3.45845952e-323], [ 3.95252517e-323, 4.44659081e-323, 4.94065646e-323, 5.43472210e-323]])\"\"\" 在构建全空数组时，可以看到数组元素均为接近于0的极小数。 可以通过arrange、linspace和random可以创建连续数组、线段型数组和随机数组： 12345678910111213141516171819array = np.arange(10,20,2) # 10-19 的数据，2步长\"\"\"array([10, 12, 14, 16, 18])\"\"\"array = np.linspace(1,10,20) # 开始端1，结束端10，且分割成20个数据，生成线段\"\"\"array([ 1. , 1.47368421, 1.94736842, 2.42105263, 2.89473684, 3.36842105, 3.84210526, 4.31578947, 4.78947368, 5.26315789, 5.73684211, 6.21052632, 6.68421053, 7.15789474, 7.63157895, 8.10526316, 8.57894737, 9.05263158, 9.52631579, 10. ])\"\"\"array = np.random.random((2,4))\"\"\"array([[ 0.94692159, 0.20821798, 0.35339414, 0.2805278 ], [ 0.04836775, 0.04023552, 0.44091941, 0.21665268]])\"\"\" 通过reshape可以改变矩阵的行列数 1234567a = np.arange(12).reshape((3,4)) # 3行4列，0到11\"\"\"array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])\"\"\" 矩阵中的运算numpy构建出的矩阵可以直接使用通用运算符计算加减乘除等，需要注意的是： 矩阵元素平方使用的是**来表示 矩阵乘法a×b为np.dot(a, b)，或者a.dot(b) 矩阵平均值和中位数的函数为mean()和median() 矩阵累加值可以使用cumsum()来计算 矩阵累差值可以使用diff()来计算 nonezero()函数：将所有非零元素的行与列坐标分割开，重构成两个分别关于行和列的矩阵。 sort()函数可以对矩阵中每行元排序 矩阵的转置可以使用transpose()或者T函数实现，在转置时，应注意单纯的array是无法转置的（如：[1,1,1]），需将其行向量才能转置 flatten()函数可以实现矩阵的扁平化 12345678910111213141516A = np.array([1,1,1])print(A.T)\"[1,1,1]\"print(A[np.newaxis,:])\"\"\"[[1 1 1]]\"\"\"print(A[:,np.newaxis])\"\"\"[[1][1][1]]\"\"\" numpy可以对索引进行一系列的运算argmin()、argmax()分别对应着求矩阵中最小元素和最大元素的索引。在Python的 list 中，我们可以利用:对一定范围内的元素进行切片操作，在Numpy中我们依然可以使用类似的方法。如：A[1, 1:3] clip(Array,Array_min,Array_max)函数可以使矩阵转换为在[min, max]范围内的矩阵，若矩阵中有大于max或小于min的元素值，则对应转换为max或min。 矩阵的合并与分割合并：横向合并np.vstack(),纵向合并np.hstack()np.concatenate()支持多个矩阵的合并，并且可以使用axis参数指定合并的维度 分割：","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://sukioosuke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sukioosuke.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://sukioosuke.github.io/tags/机器学习/"},{"name":"numpy","slug":"numpy","permalink":"https://sukioosuke.github.io/tags/numpy/"}]},{"title":"模型泛化能力","slug":"statistics-generalization-abaility","date":"2019-07-20T10:48:17.000Z","updated":"2019-07-22T07:15:50.523Z","comments":true,"path":"2019/07/20/statistics-generalization-abaility/","link":"","permalink":"https://sukioosuke.github.io/2019/07/20/statistics-generalization-abaility/","excerpt":"","text":"","raw":null,"content":null,"categories":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/tags/统计学/"},{"name":"模型","slug":"模型","permalink":"https://sukioosuke.github.io/tags/模型/"}]},{"title":"模型选择","slug":"statistics-model-choose","date":"2019-07-18T16:04:24.000Z","updated":"2019-07-22T07:15:50.527Z","comments":true,"path":"2019/07/19/statistics-model-choose/","link":"","permalink":"https://sukioosuke.github.io/2019/07/19/statistics-model-choose/","excerpt":"","text":"模型选择有两种常用方法：正则化和交叉验证 正则化正则化是结构风险最小化策略的实现。在经验风险上加一个正则项或者罚项，一般是模型复杂度的单调递增函数，模型越复杂，则正则化项的值就越大。正则化一般具有如下形式：$$ \\min_{f\\in\\mathcal{F}} \\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i))+\\lambda J(f) $$其中，第1项是经验风险，第2项是正则化项。$\\lambda \\ge 0$为调节两者比重的系数。 正则化符合奥卡姆剃刀原理，在所有可选择的模型中，能够很好的解释已知数据并且简单的才是最好的模型。 例1,L2正则化项回归问题中，损失函数是平方损失，正则化项可以是参数向量的$L_2$范数$$ L(w)=\\frac{1}{N}\\sum_{i=1}^N(f(x_i;w)-y_i)^2+\\frac{\\lambda}{2}{\\lVert w\\rVert}^2 $$这里$\\lVert w \\rVert$表示参数向量w的$L_2$范数，即$$ {\\lVert x \\rVert}{2}=\\sqrt{\\sum{i=1}^{N}{x_i^2}} $$当回归模型中的多项式项数很多时，$L_2$范数的值会收到$w_i$的影响，其中i越小，其对应的权重越重要，即经过正则化学习，高次项前的系数会变得很小，最后的曲线类似一条直线，这就是让模型变成了一个简单的模型。（具体推导可详见*[6]一文搞懂深度学习正则化的L2范数*） 正则化让模型根据训练数据中常见的模式来学习相对简单的模型，无正则化的模型用大参数学习大噪声。 L2正则化通过权重衰减，保证了模型的简单，提高了泛化能力。 例2，L0、L1正则化项当使用L0、L1正则化项时，对模型的影响是让模型的影响因子变得稀疏，进行特征自动选择。 L0正则化 L0范数指的是向量中非零元素的个数，L0正则化就是限制非零元素的个数在一定的范围，这很明显会带来稀疏。一般而言，用L0范数实现稀疏是一个NP-hard问题，因此人们一般使用L1正则化来对模型进行稀疏约束。 L1正则化L1范数是计算向量中每个元素绝对值的和,可以看出，L1范数让w向0靠近，从而对于小权重能很快的减小，对大权重减小较慢，从而使模型的权重集中在高重要度的特征上。使得最终权重w变得稀疏。$$ {\\lVert x\\rVert}1 = \\sum{i=1}^N |x_i| $$ 交叉验证另一种常用的模型选择方法是交叉验证。在数据集充沛的前提下，将数据集简单的分为三部分，分别为训练集、验证集和测试集。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。但往往在实际应用中数据并不充足，为了选择好的模型，反复的使用数据，把给定的数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复进行训练测试以及模型选择，这就是交叉验证。 简单交叉验证 随机的将已给数据分成两部分，一部分作为训练集，一部分作为测试集 用训练集在各种条件下（如不同的参数个数等）训练模型，从而得到不同的模型 在测试集上评价各个模型的测试误差，选取测试误差最小的模型 S折交叉验证S折交叉验证是目前应用最多的方法。 随机将已给数据切分为S个互不相交的大小相同的子集 利用S-1个子集的数据训练模型，利用余下的子集测试模型 对该过程可能的S种选择重复进行，最后选出S次评价中平均测试误差最小的模型 留一交叉验证留一交叉验证是S折交叉验证的特殊情况，这里S=N，N是给定数据集的数据个数。 参考文献：[1] 从高斯消元法到矩阵乘法 https://www.matongxue.com/madocs/755.html[2] 如何理解矩阵乘法？ https://www.matongxue.com/madocs/555.html[3] 如何理解相似矩阵？ https://www.matongxue.com/madocs/491.html[4] 如何理解矩阵特征值？ https://www.zhihu.com/question/21874816[5] L0、L1、L2范数在机器学习中的应用 https://www.jianshu.com/p/4bad38fe07e6[6] 一文搞懂深度学习正则化的L2范数 https://blog.csdn.net/u010725283/article/details/79212762[7] 阵与伴随矩阵的关系 https://wenku.baidu.com/view/85d3506f77c66137ee06eff9aef8941ea76e4bd1.html","raw":null,"content":null,"categories":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/tags/统计学/"},{"name":"模型","slug":"模型","permalink":"https://sukioosuke.github.io/tags/模型/"},{"name":"模型选择","slug":"模型选择","permalink":"https://sukioosuke.github.io/tags/模型选择/"}]},{"title":"oj-cpp-bits","slug":"oj-cpp-bits","date":"2019-07-08T03:20:54.000Z","updated":"2019-07-08T03:33:38.888Z","comments":true,"path":"2019/07/08/oj-cpp-bits/","link":"","permalink":"https://sukioosuke.github.io/2019/07/08/oj-cpp-bits/","excerpt":"","text":"在OJ中经常能看到C++使用头文件&lt;bits/stdc++.h&gt;，但是在本地使用简易编译器时，经常会报找不到该文件。这个文件是属于MinGW中的一个，如果安装了MinGW的直接在文件夹里面找到bits这个文件夹（注意里面一定要包含stdc++.h，有可能有两个bits文件夹），把里面内容复制粘贴到vs的头文件库（一般是在安装目录）里面。如果没有安装MinGW，在自己vs的includ目录里新建一个bits文件夹，里面新建一个名叫stdc++.h的头文件（ubuntu一般是在user/include下面），里面写你常用的头文件，这里我搬运一下stdc++.h源文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117// C++ includes used for precompiling -*- C++ -*-// Copyright (C) 2003-2015 Free Software Foundation, Inc.//// This file is part of the GNU ISO C++ Library. This library is free// software; you can redistribute it and/or modify it under the// terms of the GNU General Public License as published by the// Free Software Foundation; either version 3, or (at your option)// any later version.// This library is distributed in the hope that it will be useful,// but WITHOUT ANY WARRANTY; without even the implied warranty of// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the// GNU General Public License for more details.// Under Section 7 of GPL version 3, you are granted additional// permissions described in the GCC Runtime Library Exception, version// 3.1, as published by the Free Software Foundation.// You should have received a copy of the GNU General Public License and// a copy of the GCC Runtime Library Exception along with this program;// see the files COPYING3 and COPYING.RUNTIME respectively. If not, see// &lt;http://www.gnu.org/licenses/&gt;./** @file stdc++.h * This is an implementation file for a precompiled header. */// 17.4.1.2 Headers// C#ifndef _GLIBCXX_NO_ASSERT#include &lt;cassert&gt;#endif#include &lt;cctype&gt;#include &lt;cerrno&gt;#include &lt;cfloat&gt;#include &lt;ciso646&gt;#include &lt;climits&gt;#include &lt;clocale&gt;#include &lt;cmath&gt;#include &lt;csetjmp&gt;#include &lt;csignal&gt;#include &lt;cstdarg&gt;#include &lt;cstddef&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#include &lt;ctime&gt;#if __cplusplus &gt;= 201103L#include &lt;ccomplex&gt;#include &lt;cfenv&gt;#include &lt;cinttypes&gt;#include &lt;cstdalign&gt;#include &lt;cstdbool&gt;#include &lt;cstdint&gt;#include &lt;ctgmath&gt;#include &lt;cwchar&gt;#include &lt;cwctype&gt;#endif// C++#include &lt;algorithm&gt;#include &lt;bitset&gt;#include &lt;complex&gt;#include &lt;deque&gt;#include &lt;exception&gt;#include &lt;fstream&gt;#include &lt;functional&gt;#include &lt;iomanip&gt;#include &lt;ios&gt;#include &lt;iosfwd&gt;#include &lt;iostream&gt;#include &lt;istream&gt;#include &lt;iterator&gt;#include &lt;limits&gt;#include &lt;list&gt;#include &lt;locale&gt;#include &lt;map&gt;#include &lt;memory&gt;#include &lt;new&gt;#include &lt;numeric&gt;#include &lt;ostream&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;sstream&gt;#include &lt;stack&gt;#include &lt;stdexcept&gt;#include &lt;streambuf&gt;#include &lt;string&gt;#include &lt;typeinfo&gt;#include &lt;utility&gt;#include &lt;valarray&gt;#include &lt;vector&gt;#if __cplusplus &gt;= 201103L#include &lt;array&gt;#include &lt;atomic&gt;#include &lt;chrono&gt;#include &lt;condition_variable&gt;#include &lt;forward_list&gt;#include &lt;future&gt;#include &lt;initializer_list&gt;#include &lt;mutex&gt;#include &lt;random&gt;#include &lt;ratio&gt;#include &lt;regex&gt;#include &lt;scoped_allocator&gt;#include &lt;system_error&gt;#include &lt;thread&gt;#include &lt;tuple&gt;#include &lt;typeindex&gt;#include &lt;type_traits&gt;#include &lt;unordered_map&gt;#include &lt;unordered_set&gt;#endif","raw":null,"content":null,"categories":[{"name":"OJ","slug":"OJ","permalink":"https://sukioosuke.github.io/categories/OJ/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sukioosuke.github.io/tags/C/"},{"name":"OJ","slug":"OJ","permalink":"https://sukioosuke.github.io/tags/OJ/"}]},{"title":"统计学概论","slug":"statistics-introduction","date":"2019-07-04T13:56:25.000Z","updated":"2019-07-22T07:15:50.527Z","comments":true,"path":"2019/07/04/statistics-introduction/","link":"","permalink":"https://sukioosuke.github.io/2019/07/04/statistics-introduction/","excerpt":"","text":"统计学习是关于计算机基于数据构建概率统计模型并用模型对数据进行预测与分析的一门学科。统计学习方法是由模型、策略和算法构成的。 $$ 方法 = 模型 + 策略 + 算法 $$ 模型1.非概率模型在非概率模型中，假设空间F是由一个参数向量决定的函数族。X、Y分别代表输入空间和输出空间，θ为参数空间。$$ \\mathcal{F}={f|Y=f_\\theta(X),\\theta\\in\\mathrm{R}^n} $$ 2.概率模型在概率模型中，假设空间F是由一个参数向量决定的条件概率分布族。X、Y分别代表输入空间和输出空间，θ为参数空间。$$ \\mathcal{F}={P|P_\\theta(Y|X),\\theta\\in\\mathrm{R}^n} $$ 策略1.损失函数和风险函数常用的损失函数（代价函数）有以下几种： 0-1损失函数（0-1 loss function）$$ L(Y,f(X))=\\begin{cases}1, Y\\not=f(X) \\0, Y=f(X) \\\\end{cases}$$ 平方损失函数（quadratic loss function）$$ L(Y,f(X))=(Y-f(X))^2 $$ 绝对损失函数（absolute loss function）$$ L(Y,f(X))=|Y-f(X)| $$ 对数损失函数（logarithmic loss function）（对数似然损失函数）$$ L(Y,P(Y|X))=-logP(Y|X) $$ 损失函数的期望即风险函数，模型f(X)关于联合分布P(X,Y)的平均意义下的损失。$$ R_{exp}(f)=E_P[L(Y,f(X))]=\\int_{\\mathcal{X}\\times\\mathcal{Y}}L(y,f(x))P(x,y)dxdy $$学习的目标就是选择期望风险最小的模型，但P(X,Y)是未知的，故$R_{exp}(f)$不能直接计算。从而对训练数据集计算经验损失$R_{emp}(f)$:$$ R_{emp}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i)) $$在N趋于无穷是，$R_{emp}(f)$趋近于$R_{exp}(f)$。但是实验中训练样本数有限，所以要对经验风险进行一定的矫正，在矫正总有两个基本策略：①经验风险最小化和②结构风险最小化。 2.经验风险最小化和结构风险最小化1)经验风险最小化（ERM）经验风险最小化的策略认为，经验风险最小的模型就是最优的模型。根据这一策略，可转化为求解最优化问题：$$ \\min_{f\\in\\mathcal{F}} \\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i)) $$但是当样本容量很小时，经验风险最小化学习就可能会出现过拟合现象。 2)结构风险最小化（SRM）结构风险最小化等价于正则化，有效的防止了过拟合。结构风险在经验风险上加上表示模型复杂度的正则化项或者罚项。结构风险的定义为：$$ R_{srm}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i))+\\lambda J(f) $$J(f)表示模型的复杂度，$/lamda$是系数，用于权衡经验风险和模型复杂度。即求最优模型，就是求解最优化问题$\\min_{f\\in\\mathcal{F}} R_{srm}F$ 算法算法是指学习模型的具体计算方法。统计学习的问题是最优化问题，统计学习算法也就是求解最优化问题的算法。要找到全局最优解，并且求解过程要高效。","raw":null,"content":null,"categories":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/categories/统计学/"}],"tags":[{"name":"统计学","slug":"统计学","permalink":"https://sukioosuke.github.io/tags/统计学/"},{"name":"损失函数","slug":"损失函数","permalink":"https://sukioosuke.github.io/tags/损失函数/"},{"name":"代价函数","slug":"代价函数","permalink":"https://sukioosuke.github.io/tags/代价函数/"}]},{"title":"python中的yield关键字","slug":"python-yield","date":"2019-07-02T08:47:06.000Z","updated":"2019-07-18T10:48:48.208Z","comments":true,"path":"2019/07/02/python-yield/","link":"","permalink":"https://sukioosuke.github.io/2019/07/02/python-yield/","excerpt":"","text":"今天在看别人的代码时遇到了yield关键字，当时学python的时候学的并不扎实，现在做个总结 yield example一个网上经常列举的yield的例子： 12345def node._get_child_candidates(self, distance, min_dist, max_dist): if self._leftchild and distance - max_dist &lt; self._median: yield self._leftchild if self._rightchild and distance + max_dist &gt;= self._median: yield self._rightchild 下面是具体调用时的执行 12345678result, candidates = list(), [self]while candidates: node = candidates.pop() distance = node._get_dist(obj) if distance &lt;= max_dist and distance &gt;= min_dist: result.extend(node._values) candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))return result 调用_get_child_candidates时，返回了一个child的合集（list），yield是如何生成这个对象的呢？ 先来看一下可迭代对象当你建立了一个列表，你可以逐项地读取这个列表，这叫做一个可迭代对象: 123456&gt;&gt;&gt; mylist = [1, 2, 3]&gt;&gt;&gt; for i in mylist :... print(i)123 mylist是一个可迭代的对象。当你使用一个列表生成式来建立一个列表的时候，同样生成了一个可迭代的对象: 123456&gt;&gt;&gt; mylist = [x for x in range(3)]&gt;&gt;&gt; for i in mylist :... print(i)012 可以通过for循环读取的对象就是一个迭代器，其元素在遍历访问时均存储在了内存中，如果要大量访问数据的话，迭代器的方式是很占用资源的 生成器生成器是可以迭代的对象，但是你只需读取一次，它可以在调用时实时生成数据，而不是将数据都存放在内存中。 123456&gt;&gt;&gt; mygenerator = (x for x in range(3))&gt;&gt;&gt; for i in mygenerator :... print(i)012 虽然只是把(换成了[，但是对于生成器而言，只能迭代一次，而且也从迭代器变成了生成器。 回到yield关键字yield关键字在调用后会返回一个类似于mygenerator的生成器，类似于返回生成器的return关键字。 12345678910111213&gt;&gt;&gt; def createGenerator() :... mylist = range(3)... for i in mylist :... yield i*i...&gt;&gt;&gt; mygenerator = createGenerator() # create a generator&gt;&gt;&gt; print(mygenerator) # mygenerator is an object!&lt;generator object createGenerator at 0xb7555c34&gt;&gt;&gt;&gt; for i in mygenerator:... print(i)014 在执行for i in mygenerator时，到达yield关键字时，返回yield后的值作为第一次迭代的返回值. 然后，每次执行这个函数都会继续返回定义的迭代值，直到没有可以返回的。带有yield的函数不仅仅只用于for循环中，而且可用于某个函数的参数，只要这个函数的参数允许迭代参数。比如array.extend函数，它的原型是array.extend(iterable)。 此处应注意的是，生成器的方法虽然可以调用多次，获取多个迭代结果，但生成器只会实例化一次，既实例化后的生成器可以通过变量等来控制生成器的生成与穷尽。可参考如下代码： 1234567891011121314151617181920212223242526272829303132333435&gt;&gt;&gt; class Bank(): # let's create a bank, building ATMs... crisis = False... def create_atm(self) :... while not self.crisis :... yield \"$100\"&gt;&gt;&gt; hsbc = Bank() # when everything's ok the ATM gives you as much as you want&gt;&gt;&gt; corner_street_atm = hsbc.create_atm()&gt;&gt;&gt; print(corner_street_atm.__next__()())$100&gt;&gt;&gt; print(corner_street_atm.__next__()())$100&gt;&gt;&gt; print([corner_street_atm.__next__()() for cash in range(5)])['$100', '$100', '$100', '$100', '$100']&gt;&gt;&gt; hsbc.crisis = True # crisis is coming, no more money!&gt;&gt;&gt; print(corner_street_atm.__next__()())&lt;type 'exceptions.StopIteration'&gt;&gt;&gt;&gt; wall_street_atm = hsbc.create_atm() # it's even true for new ATMs&gt;&gt;&gt; print(wall_street_atm.__next__()())&lt;type 'exceptions.StopIteration'&gt;&gt;&gt;&gt; hsbc.crisis = False # trouble is, even post-crisis the ATM remains empty&gt;&gt;&gt; print(corner_street_atm.__next__()())&lt;type 'exceptions.StopIteration'&gt;&gt;&gt;&gt; brand_new_atm = hsbc.create_atm() # build a new one to get back in business&gt;&gt;&gt; for cash in brand_new_atm :... print cash$100$100$100$100$100$100$100$100$100... 迭代器的操作生成器只能实例化一次，这就为我们的复用造成一些麻烦，如果需要两个一模一样但是相互独立的生成器怎么办呢？itertools提供了很多特殊的迭代方法，包括复制一个迭代器，串联迭代器，把嵌套的列表分组等等等，这个类从一定程度上解决了生成器的复用问题。如果想要动态变化生成器的内容呢？生成器本身除去next方法外，还有一个send(msg)的方法，send(msg)与next()的区别在于send可以传递参数给yield表达式，这时传递的参数会作为yield表达式的值，而yield的参数是返回给调用者的值。比如函数中有一个yield赋值，a = yield 5，第一次迭代到这里会返回5，a还没有赋值。第二次迭代时，使用.send(10)，那么，就是强行修改yield 5表达式的值为10，本来是5的，而现在a=10。可以认为，next()等同于send(None)。 此处应注意的是，第一次调用时必须先next()或send(None)，否则会报错，因为这时候没有上一个yield值。 关于迭代器的内部原理迭代是一个实现可迭代对象(实现的是__iter__()方法)和迭代器(实现的是__next__()方法)的过程。可迭代对象是你可以从其获取到一个迭代器的任一对象。迭代器是那些允许你迭代可迭代对象的对象。 参考文献：https://pyzh.readthedocs.io/en/latest/the-python-yield-keyword-explained.html#yield","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://sukioosuke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sukioosuke.github.io/tags/python/"}]},{"title":"Hello World!","slug":"Hello-World","date":"2019-06-25T09:39:24.000Z","updated":"2019-07-18T10:48:48.208Z","comments":true,"path":"2019/06/25/Hello-World/","link":"","permalink":"https://sukioosuke.github.io/2019/06/25/Hello-World/","excerpt":"","text":"之前一直想找个工具记录一下自己的所学所想，开始在csdn做简单的记录，后来改版后每次写的时候都要花费不少功夫要写，就慢慢放弃了。这次在git用hexo自建blog，可以避免这个问题，也可以让自己坚持下去。blog主要用于： 整理知识，学习笔记 发布日记，杂文，所见所想 整理技术文稿（代码） 别人的赏识都是过眼云烟，只有自己的提高进步才是真金白银！ p.s. 在线md编写工具 LaTex符号","raw":null,"content":null,"categories":[{"name":"随笔","slug":"随笔","permalink":"https://sukioosuke.github.io/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://sukioosuke.github.io/tags/随笔/"}]}]}